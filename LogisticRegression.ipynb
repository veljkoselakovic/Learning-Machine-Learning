{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCT7CmMcacMX5hX7VJPfpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veljkoselakovic/Python-Machine-Learning-Raschka/blob/main/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTOlK1PyIrsG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcELaek2JE5j"
      },
      "source": [
        "**Sigmoid function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpcwi8ToI-0F"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0 / (1.0 + np.exp(-z)))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7E93d9aJXZ7"
      },
      "source": [
        "<center><b>error cost function</b></center>\n",
        "---\n",
        "\n",
        "$$J(\\omega) = \\sum_{i} \\frac{1}{2} (\\phi(z^{(i)}) - y^{(i)})^2 $$ \n",
        "\n",
        "\n",
        "<center><b>confidence</b></center>\n",
        "\n",
        "---\n",
        "$$L(\\omega) = P (y | x; \\omega) = \\prod_{i=1}^{n} P(y^{(i)}|x^{(i)}; \\omega) = \\prod_{i=1}^{n} (\\phi(z^{(i)}))^{y^{(i)}} (1 - \\phi(z^{(i)}))^{1-y^{(i)}}$$\n",
        "\n",
        "log $L(\\omega)$ ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtTLNEsoMyvy"
      },
      "source": [
        "**LogisticRegression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYj4X0HqJIke"
      },
      "source": [
        "class LogisticRegressionGD(object):\n",
        "  def __init__(self, eta = 0.05, n_iter = 100, random_state = 1):\n",
        "    self.eta = eta\n",
        "    self.n_iter = n_iter\n",
        "    self.random_state = random_state\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    rgen = np.random.RandomState(self.random_state)\n",
        "    self.w_ = rgen.normal(loc=0.0, scale=0.01, size = 1 + X.shape[1])\n",
        "    self.cost_ = []\n",
        "    for i in range(self.n_iter):\n",
        "      net_input = self.net_input(x)\n",
        "      output = self.activation(net_input)\n",
        "      errors = (y - output)\n",
        "      self.w_[1:] += self.eta * X.T.dot(errors)\n",
        "      self.w_[0] += self.eta * errors.sum()\n",
        "      cost = (-y.dot(np.log(output)) - ((1-y).dot(np.log(1-output))))\n",
        "      self.cost_append(cost)\n",
        "    return self\n",
        "\n",
        "  def net_input(self, x):\n",
        "    return np.dot(x, self.w_[1:]) + self.w_[0]\n",
        "  def activation(self, x):\n",
        "    return 1. / (1. + np.exp(-np.clip(x, -250, 250)))\n",
        "  def predict(self, x):\n",
        "    return np.where(self.net_input(x)>= 0.0, 1, 0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pYuyGbKMvJi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}